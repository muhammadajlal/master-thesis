arch_de: 'ar_transformer_s' # decoder architecture
freeze_decoder_epochs: 99999999 # Ablation: freeze AR decoder for first N epochs (0 = train end-to-end from start)
pretrained_decoder_checkpoint: /home/woody/iwso/iwso214h/imu-hwr/results/hwr2/pretrain_ar_decoder_char_100/run_1512332/0/checkpoints/best_loss.pth

arch_en: 'blconv_b'
aug: true # whether to perform data augmentation for train set
cache: true # whether to cache the whole dataset into rams
checkpoint: null # path to checkpoint to load
ctc_decoder: best_path
device: cuda

dir_dataset: /home/woody/iwso/iwso214h/imu-hwr/data/onhw_wi_word_rh
dir_work: /home/woody/iwso/iwso214h/imu-hwr/results/hwr2/train_element_word_freeze_complete/ar_transformer_s__onhw_wi_word_rh

epoch: 300
# We also can set epoch_warmup to 10 for more quick debugging.
epoch_warmup: 30
freeze: false # whether to freeze the encoder
freq_eval: 5 # frequency (epoch) to evaulate model performance on val set
freq_log: 50 # frequency (iteration) to log information
freq_save: 5 # frequency (epoch) to save model checkpoint
save_best_only: true # whether to save only the best checkpoints during training
export_val_full: false # whether to export full val set decoding results during training
idx_fold: 0 # cross validation fold index. 0 for non-cross validation. -1 for train for all cross-validation folds automatically
len_seq: 0
lr: 0.001
num_channel: 13
num_worker: 16
seed: 42
size_batch: 64
test: false

tokenizer:
  type: sentencepiece
  model: /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/tokenizer/bpe100.model
  vocab_size: 100
use_bpe: false
# Only for transformer decoder
use_gated_attention: true
gating_type: elementwise # options: "elementwise", "headwise"

categories: ["", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "Ä", "Ö", "Ü", "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "ä", "ö", "ü", "ß"] # including seperation label "" for CTC

# For sentence-level dataset
#categories: ["", "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "ä", "ö", "ü", "Ä", "Ö", "Ü", "ß", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", ".", ",", "(",")", "'", "?", "!", "+", "=", "-", "/", ";", ":", "·", " "] 
 