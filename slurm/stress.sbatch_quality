#!/bin/bash
#SBATCH -J stress-ar
#SBATCH -p rtx3080
#SBATCH --gres=gpu:rtx3080:1
#SBATCH --cpus-per-task=8
#SBATCH -t 02:00:00
#SBATCH -o stress-ar_%j.out
#SBATCH -e stress-ar_%j.err

set -euo pipefail
set -x

module load python/3.12-conda 2>/dev/null || true
source /apps/python/3.12-conda/etc/profile.d/conda.sh
conda activate /home/woody/iwso/iwso214h/imu-hwr/envs/rewi

cd /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work

# Where to write the capacity CSV + per-length GT/Pred CSVs
CAP_OUT="stress_results_${SLURM_JOB_ID}.csv"
QUAL_DIR="stress_outputs_${SLURM_JOB_ID}"

# Capacity + Quality:
# - lengths: very long inputs (16k, 32k, 65k). Add smaller if you want a ramp: e.g., 4096,8192,...
# - batches: keep 64 to mirror training; reduce if you hit OOM
# - steps_list: AR decode steps per trial (keep reasonable to avoid runaway time)
# - --run_quality: computes CER/WER on REAL concatenated samples from val.json
# - --items_per_concat 4: ~ concatenate 4 items per sample (still padded to a common T per batch)
# - --eval_batch 8: eval batch for the quality pass
python stress_test_decoder.py \
  -c configs/train.yaml \
  --device cuda \
  --amp --tf32 \
  --lengths 1024,2048,4096,16384,32768 \
  --batches 64 \
  --steps_list 64,128,256 \
  --csv "${CAP_OUT}" \
  --run_quality \
  --data_split val \
  --items_per_concat 4 \
  --eval_batch 8 \
  --quality_dir "${QUAL_DIR}"

echo "==== DONE ===="
echo "Capacity CSV:    ${CAP_OUT}"
echo "Quality outputs: ${QUAL_DIR}/gt_pred_T*.csv (plus CER/WER logs in stdout)"
