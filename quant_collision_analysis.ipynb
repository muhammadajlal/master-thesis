{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNIFIED_CSV exists: True | /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/quant_all_val_predictions_new.csv\n",
            "OUT_DIR: /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/collision_redo\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Config (EDIT THESE)\n",
        "# ---------------------------\n",
        "\n",
        "# Unified predictions CSV (semicolon-separated)\n",
        "UNIFIED_CSV = Path(\"/home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/quant_all_val_predictions_new.csv\")\n",
        "# If you want to run against the attached file in this chat instead:\n",
        "# UNIFIED_CSV = Path(\"/mnt/data/quant_all_val_predictions_new.csv\")\n",
        "\n",
        "OUT_DIR = Path(\"/home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/collision_redo\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 1337\n",
        "\n",
        "print(\"UNIFIED_CSV exists:\", UNIFIED_CSV.exists(), \"|\", UNIFIED_CSV)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 2 — Load unified CSV and build normalized strings + UID\n",
        "\n",
        "This normalization is intentionally minimal (and consistent with the sent_collisions_norm.csv logic): lowercasing + whitespace collapse + Unicode normalization. We also define “error” as pred_norm != lab_norm (this matches the behavior that excludes pure case/formatting differences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 44802\n",
            "   task  fold                                          json_path  \\\n",
            "0  sent     0  /home/woody/iwso/iwso214h/imu-hwr/work/REWI_wo...   \n",
            "1  sent     0  /home/woody/iwso/iwso214h/imu-hwr/work/REWI_wo...   \n",
            "2  sent     0  /home/woody/iwso/iwso214h/imu-hwr/work/REWI_wo...   \n",
            "\n",
            "   sample_index                                     prediction  \\\n",
            "0             0                                  Du bist dran.   \n",
            "1             1  Lass/Lasst uns hingehen!; Los, gehen wir hin!   \n",
            "2             2                              Ich hole sie/ihn.   \n",
            "\n",
            "                                           label  levenshtein_distance  \\\n",
            "0                                  Du bist dran.                     0   \n",
            "1  Lass/Lasst uns hingehen!; Los, gehen wir hin!                     0   \n",
            "2                              Ich hole sie/ihn.                     0   \n",
            "\n",
            "        uid                                      pred_norm  \\\n",
            "0  sent|0|0                                  du bist dran.   \n",
            "1  sent|0|1  lass/lasst uns hingehen!; los, gehen wir hin!   \n",
            "2  sent|0|2                              ich hole sie/ihn.   \n",
            "\n",
            "                                        lab_norm  lev_pred_gt  \n",
            "0                                  du bist dran.            0  \n",
            "1  lass/lasst uns hingehen!; los, gehen wir hin!            0  \n",
            "2                              ich hole sie/ihn.            0  \n"
          ]
        }
      ],
      "source": [
        "def norm_str(s: object) -> str:\n",
        "    \"\"\"Minimal normalization used for collision matching.\"\"\"\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "df = pd.read_csv(UNIFIED_CSV, sep=\";\")\n",
        "\n",
        "required_cols = {\"task\", \"fold\", \"sample_index\", \"prediction\", \"label\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Unified CSV is missing columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "# Create UID identical in spirit to existing outputs: task|fold|sample_index\n",
        "df[\"fold\"] = df[\"fold\"].astype(int)\n",
        "df[\"sample_index\"] = df[\"sample_index\"].astype(int)\n",
        "df[\"uid\"] = df.apply(lambda r: f\"{r['task']}|{r['fold']}|{r['sample_index']}\", axis=1)\n",
        "\n",
        "df[\"pred_norm\"] = df[\"prediction\"].map(norm_str)\n",
        "df[\"lab_norm\"]  = df[\"label\"].map(norm_str)\n",
        "\n",
        "# Optional (kept if available)\n",
        "if \"levenshtein_distance\" in df.columns:\n",
        "    df[\"lev_pred_gt\"] = df[\"levenshtein_distance\"].astype(int)\n",
        "else:\n",
        "    df[\"lev_pred_gt\"] = np.nan  # keep column for schema compatibility\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(df.head(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 3 — Build collisions CSV for BOTH tasks with the SAME schema as sent_collisions_norm.csv\n",
        "\n",
        "This produces a single event table with columns:\n",
        "fold, sample_index, uid, prediction, label, lev_pred_gt, match_fold, match_sample_index, match_uid, match_label, match_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collision events: 66043\n",
            "By task (inferred from uid prefix):\n",
            "0\n",
            "word    41576\n",
            "sent    24467\n",
            "Name: count, dtype: int64\n",
            "Wrote: /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/collision_redo/collisions_norm_all_tasks.csv\n"
          ]
        }
      ],
      "source": [
        "# Error samples are defined by normalized mismatch (matches original collision logic)\n",
        "err = df[df[\"pred_norm\"] != df[\"lab_norm\"]].copy()\n",
        "\n",
        "# Candidate match table: any ground-truth label can be a collision target\n",
        "match_tbl = df[[\"task\", \"fold\", \"sample_index\", \"uid\", \"label\", \"lab_norm\"]].copy()\n",
        "match_tbl = match_tbl.rename(columns={\n",
        "    \"fold\": \"match_fold\",\n",
        "    \"sample_index\": \"match_sample_index\",\n",
        "    \"uid\": \"match_uid\",\n",
        "    \"label\": \"match_label\",\n",
        "    \"lab_norm\": \"match_lab_norm\",\n",
        "})\n",
        "\n",
        "# Collision event: pred_norm of an error equals lab_norm of some other sample in same task\n",
        "coll = err.merge(\n",
        "    match_tbl,\n",
        "    left_on=[\"task\", \"pred_norm\"],\n",
        "    right_on=[\"task\", \"match_lab_norm\"],\n",
        "    how=\"inner\",\n",
        ")\n",
        "\n",
        "# Keep EXACT schema (plus match_type)\n",
        "coll_out = coll.rename(columns={\"levenshtein_distance\": \"lev_pred_gt\"})  # if present already\n",
        "coll_out[\"match_type\"] = \"pred_norm == lab_norm\"\n",
        "\n",
        "# Column order identical to sent_collisions_norm.csv\n",
        "cols = [\n",
        "    \"fold\", \"sample_index\", \"uid\", \"prediction\", \"label\", \"lev_pred_gt\",\n",
        "    \"match_fold\", \"match_sample_index\", \"match_uid\", \"match_label\", \"match_type\"\n",
        "]\n",
        "coll_out = coll_out[cols].copy()\n",
        "\n",
        "print(\"Collision events:\", len(coll_out))\n",
        "print(\"By task (inferred from uid prefix):\")\n",
        "print(coll_out[\"uid\"].str.split(\"|\", n=1, expand=True)[0].value_counts())\n",
        "\n",
        "# Save\n",
        "COLLISIONS_CSV = OUT_DIR / \"collisions_norm_all_tasks.csv\"\n",
        "coll_out.to_csv(COLLISIONS_CSV, index=False)\n",
        "print(\"Wrote:\", COLLISIONS_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coll_raw shape: (66043, 16)\n"
          ]
        }
      ],
      "source": [
        "# If match_type exists, keep only raw collisions (as per your decision).\n",
        "coll_raw = coll.copy()\n",
        "print(\"coll_raw shape:\", coll_raw.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 4 — Check 1: collision label-frequency concentration (UID-weighted + event-weighted)\n",
        "\n",
        "This regenerates the exact distributional table you described, and saves:\n",
        "\n",
        "collision_gtfreq_summary.csv\n",
        "\n",
        "a LaTeX table snippet you can paste into the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>View</th>\n",
              "      <th>n</th>\n",
              "      <th>Median</th>\n",
              "      <th>p90</th>\n",
              "      <th>p95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence</td>\n",
              "      <td>UID-weighted</td>\n",
              "      <td>1712</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence</td>\n",
              "      <td>Event-weighted</td>\n",
              "      <td>24467</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Word</td>\n",
              "      <td>UID-weighted</td>\n",
              "      <td>2845</td>\n",
              "      <td>14</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Word</td>\n",
              "      <td>Event-weighted</td>\n",
              "      <td>41576</td>\n",
              "      <td>19</td>\n",
              "      <td>31</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset            View      n  Median  p90  p95\n",
              "0  Sentence    UID-weighted   1712      15   21   23\n",
              "1  Sentence  Event-weighted  24467      17   23   25\n",
              "2      Word    UID-weighted   2845      14   26   29\n",
              "3      Word  Event-weighted  41576      19   31   40"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/collision_redo/collision_gtfreq_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# Ground-truth label frequency per task (on normalized labels)\n",
        "label_counts = (\n",
        "    df.groupby([\"task\", \"lab_norm\"])\n",
        "      .size()\n",
        "      .rename(\"gt_label_count\")\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Attach pred_norm and gt_label_count(pred_norm) to collision events\n",
        "coll_aug = coll_out.merge(df[[\"uid\", \"task\", \"pred_norm\"]], on=\"uid\", how=\"left\")\n",
        "coll_aug = coll_aug.merge(\n",
        "    label_counts,\n",
        "    left_on=[\"task\", \"pred_norm\"],\n",
        "    right_on=[\"task\", \"lab_norm\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "assert coll_aug[\"gt_label_count\"].isna().sum() == 0, \"Unexpected: collision pred not found in label counts.\"\n",
        "\n",
        "def summarize_counts(values: np.ndarray) -> dict:\n",
        "    values = np.asarray(values, dtype=float)\n",
        "    return {\n",
        "        \"n\": int(values.size),\n",
        "        \"Median\": int(np.median(values)),\n",
        "        \"p90\": int(np.percentile(values, 90)),\n",
        "        \"p95\": int(np.percentile(values, 95)),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for task in [\"sent\", \"word\"]:\n",
        "    name = \"Sentence\" if task == \"sent\" else \"Word\"\n",
        "\n",
        "    # UID-weighted: one per colliding error sample (uid)\n",
        "    uid_vals = (\n",
        "        coll_aug[coll_aug[\"task\"] == task]\n",
        "        .drop_duplicates(\"uid\")[\"gt_label_count\"]\n",
        "        .to_numpy()\n",
        "    )\n",
        "    rows.append({\"Dataset\": name, \"View\": \"UID-weighted\", **summarize_counts(uid_vals)})\n",
        "\n",
        "    # Event-weighted: one per collision event\n",
        "    ev_vals = coll_aug[coll_aug[\"task\"] == task][\"gt_label_count\"].to_numpy()\n",
        "    rows.append({\"Dataset\": name, \"View\": \"Event-weighted\", **summarize_counts(ev_vals)})\n",
        "\n",
        "summary_df = pd.DataFrame(rows)[[\"Dataset\", \"View\", \"n\", \"Median\", \"p90\", \"p95\"]]\n",
        "display(summary_df)\n",
        "\n",
        "# Save CSV for report\n",
        "SUMMARY_CSV = OUT_DIR / \"collision_gtfreq_summary.csv\"\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "print(\"Wrote:\", SUMMARY_CSV)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 5 — “Most frequent collided predictions” for your “next steps” list\n",
        "\n",
        "This produces a per-task ranking of collided predicted strings, together with gt_label_count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/collision_redo/top_collided_predictions_by_task.csv\n",
            "\n",
            "=== Top collided predictions: sent ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>pred_norm</th>\n",
              "      <th>gt_label_count</th>\n",
              "      <th>collision_event_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>sent</td>\n",
              "      <td>inlineskatesfahren ist toll.</td>\n",
              "      <td>17</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>sent</td>\n",
              "      <td>soziales netzwerk</td>\n",
              "      <td>21</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>sent</td>\n",
              "      <td>rappe/rappt wie ich.</td>\n",
              "      <td>27</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>sent</td>\n",
              "      <td>handlungsort; lage; standort</td>\n",
              "      <td>17</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>sent</td>\n",
              "      <td>los; ticket; eintrittskarte</td>\n",
              "      <td>17</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>sent</td>\n",
              "      <td>tour; fahrt; rundgang</td>\n",
              "      <td>19</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>sent</td>\n",
              "      <td>paket; päckchen</td>\n",
              "      <td>25</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>sent</td>\n",
              "      <td>verletzen; weh tun</td>\n",
              "      <td>18</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>sent</td>\n",
              "      <td>problem; schwierigkeit</td>\n",
              "      <td>23</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>sent</td>\n",
              "      <td>klub; verein; ag</td>\n",
              "      <td>27</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>sent</td>\n",
              "      <td>story; geschichte; erzählung</td>\n",
              "      <td>22</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>sent</td>\n",
              "      <td>aussage; behauptung; erklärung</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>sent</td>\n",
              "      <td>zur selben zeit; gleichzeitig</td>\n",
              "      <td>25</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>sent</td>\n",
              "      <td>der; die; das; dem; den (relativpronomen)</td>\n",
              "      <td>15</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>sent</td>\n",
              "      <td>glücksbringer; talisman</td>\n",
              "      <td>20</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     task                                  pred_norm  gt_label_count  \\\n",
              "344  sent               inlineskatesfahren ist toll.              17   \n",
              "561  sent                          soziales netzwerk              21   \n",
              "481  sent                       rappe/rappt wie ich.              27   \n",
              "259  sent               handlungsort; lage; standort              17   \n",
              "405  sent                los; ticket; eintrittskarte              17   \n",
              "717  sent                      tour; fahrt; rundgang              19   \n",
              "460  sent                            paket; päckchen              25   \n",
              "748  sent                         verletzen; weh tun              18   \n",
              "470  sent                     problem; schwierigkeit              23   \n",
              "384  sent                           klub; verein; ag              27   \n",
              "575  sent               story; geschichte; erzählung              22   \n",
              "78   sent             aussage; behauptung; erklärung              16   \n",
              "820  sent              zur selben zeit; gleichzeitig              25   \n",
              "136  sent  der; die; das; dem; den (relativpronomen)              15   \n",
              "245  sent                    glücksbringer; talisman              20   \n",
              "\n",
              "     collision_event_count  \n",
              "344                    187  \n",
              "561                    168  \n",
              "481                    162  \n",
              "259                    153  \n",
              "405                    153  \n",
              "717                    152  \n",
              "460                    150  \n",
              "748                    144  \n",
              "470                    138  \n",
              "384                    135  \n",
              "575                    132  \n",
              "78                     128  \n",
              "820                    125  \n",
              "136                    120  \n",
              "245                    120  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top collided predictions: word ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>pred_norm</th>\n",
              "      <th>gt_label_count</th>\n",
              "      <th>collision_event_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>word</td>\n",
              "      <td>land</td>\n",
              "      <td>67</td>\n",
              "      <td>1139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>word</td>\n",
              "      <td>uhr</td>\n",
              "      <td>40</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1831</th>\n",
              "      <td>word</td>\n",
              "      <td>sehr</td>\n",
              "      <td>29</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049</th>\n",
              "      <td>word</td>\n",
              "      <td>vor</td>\n",
              "      <td>28</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>word</td>\n",
              "      <td>klein</td>\n",
              "      <td>27</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>word</td>\n",
              "      <td>kommen</td>\n",
              "      <td>26</td>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>word</td>\n",
              "      <td>material</td>\n",
              "      <td>28</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>word</td>\n",
              "      <td>kochen</td>\n",
              "      <td>34</td>\n",
              "      <td>238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>word</td>\n",
              "      <td>erkältung</td>\n",
              "      <td>23</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>word</td>\n",
              "      <td>schnell</td>\n",
              "      <td>46</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>word</td>\n",
              "      <td>gestern</td>\n",
              "      <td>28</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>word</td>\n",
              "      <td>ufer</td>\n",
              "      <td>44</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860</th>\n",
              "      <td>word</td>\n",
              "      <td>so</td>\n",
              "      <td>23</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2155</th>\n",
              "      <td>word</td>\n",
              "      <td>zug</td>\n",
              "      <td>29</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>word</td>\n",
              "      <td>schatz</td>\n",
              "      <td>32</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      task  pred_norm  gt_label_count  collision_event_count\n",
              "1435  word       land              67                   1139\n",
              "1994  word        uhr              40                    400\n",
              "1831  word       sehr              29                    319\n",
              "2049  word        vor              28                    308\n",
              "1391  word      klein              27                    270\n",
              "1398  word     kommen              26                    260\n",
              "1506  word   material              28                    252\n",
              "1395  word     kochen              34                    238\n",
              "1120  word  erkältung              23                    230\n",
              "1805  word    schnell              46                    230\n",
              "1243  word    gestern              28                    224\n",
              "1993  word       ufer              44                    220\n",
              "1860  word         so              23                    207\n",
              "2155  word        zug              29                    203\n",
              "1784  word     schatz              32                    192"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "top = (\n",
        "    coll_aug.groupby([\"task\", \"pred_norm\", \"gt_label_count\"])\n",
        "            .size()\n",
        "            .rename(\"collision_event_count\")\n",
        "            .reset_index()\n",
        "            .sort_values([\"task\", \"collision_event_count\"], ascending=[True, False])\n",
        ")\n",
        "\n",
        "TOP_CSV = OUT_DIR / \"top_collided_predictions_by_task.csv\"\n",
        "top.to_csv(TOP_CSV, index=False)\n",
        "print(\"Wrote:\", TOP_CSV)\n",
        "\n",
        "# Show top 15 per task\n",
        "for task in [\"sent\", \"word\"]:\n",
        "    print(\"\\n=== Top collided predictions:\", task, \"===\")\n",
        "    display(top[top[\"task\"] == task].head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 7 — Curate pairs: collision (i,j) vs random baseline (i,k), same fold and task\n",
        "\n",
        "This matches your stated protocol (same fold + dataset for the random baseline)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell 8 — Compute similarities (with caching) and summarize Check 2 outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SENT ===\n",
            "collision events=24467 | unique colliding error samples=1712\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>collision_events</th>\n",
              "      <th>event_share_%</th>\n",
              "      <th>unique_error_samples</th>\n",
              "      <th>uid_share_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Inlineskatesfahren ist toll.</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.764295</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.642523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>soziales Netzwerk</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.686639</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.467290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Rappe/Rappt wie ich.</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.662116</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Handlungsort; Lage; Standort</td>\n",
              "      <td>153.0</td>\n",
              "      <td>0.625332</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.525701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Los; Ticket; Eintrittskarte</td>\n",
              "      <td>153.0</td>\n",
              "      <td>0.625332</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.525701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Tour; Fahrt; Rundgang</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.621245</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.467290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Paket; Päckchen</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.613071</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.350467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>verletzen; weh tun</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.588548</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.467290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Problem; Schwierigkeit</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.564025</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.350467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Klub; Verein; AG</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.551764</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      prediction  collision_events  event_share_%  \\\n",
              "6   Inlineskatesfahren ist toll.             187.0       0.764295   \n",
              "23             soziales Netzwerk             168.0       0.686639   \n",
              "11          Rappe/Rappt wie ich.             162.0       0.662116   \n",
              "4   Handlungsort; Lage; Standort             153.0       0.625332   \n",
              "8    Los; Ticket; Eintrittskarte             153.0       0.625332   \n",
              "13         Tour; Fahrt; Rundgang             152.0       0.621245   \n",
              "9                Paket; Päckchen             150.0       0.613071   \n",
              "24            verletzen; weh tun             144.0       0.588548   \n",
              "10        Problem; Schwierigkeit             138.0       0.564025   \n",
              "7               Klub; Verein; AG             135.0       0.551764   \n",
              "\n",
              "    unique_error_samples  uid_share_%  \n",
              "6                   11.0     0.642523  \n",
              "23                   8.0     0.467290  \n",
              "11                   0.0     0.000000  \n",
              "4                    9.0     0.525701  \n",
              "8                    9.0     0.525701  \n",
              "13                   8.0     0.467290  \n",
              "9                    6.0     0.350467  \n",
              "24                   8.0     0.467290  \n",
              "10                   6.0     0.350467  \n",
              "7                    0.0     0.000000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 share (events): 6.30%\n",
            "Top-10 share (unique errors): 4.96%\n",
            "\n",
            "=== WORD ===\n",
            "collision events=41576 | unique colliding error samples=2845\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>collision_events</th>\n",
              "      <th>event_share_%</th>\n",
              "      <th>unique_error_samples</th>\n",
              "      <th>uid_share_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Land</td>\n",
              "      <td>871.0</td>\n",
              "      <td>2.094959</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.456942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Uhr</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.962094</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.351494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>sehr</td>\n",
              "      <td>319.0</td>\n",
              "      <td>0.767270</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.386643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>vor</td>\n",
              "      <td>308.0</td>\n",
              "      <td>0.740812</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.386643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>klein</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.649413</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.351494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>land</td>\n",
              "      <td>268.0</td>\n",
              "      <td>0.644603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>kommen</td>\n",
              "      <td>234.0</td>\n",
              "      <td>0.562825</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.316344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Erkältung</td>\n",
              "      <td>230.0</td>\n",
              "      <td>0.553204</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.351494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>schnell</td>\n",
              "      <td>230.0</td>\n",
              "      <td>0.553204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>gestern</td>\n",
              "      <td>224.0</td>\n",
              "      <td>0.538772</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.281195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   prediction  collision_events  event_share_%  unique_error_samples  \\\n",
              "6        Land             871.0       2.094959                  13.0   \n",
              "12        Uhr             400.0       0.962094                  10.0   \n",
              "21       sehr             319.0       0.767270                  11.0   \n",
              "25        vor             308.0       0.740812                  11.0   \n",
              "16      klein             270.0       0.649413                  10.0   \n",
              "18       land             268.0       0.644603                   0.0   \n",
              "17     kommen             234.0       0.562825                   9.0   \n",
              "2   Erkältung             230.0       0.553204                  10.0   \n",
              "20    schnell             230.0       0.553204                   0.0   \n",
              "15    gestern             224.0       0.538772                   8.0   \n",
              "\n",
              "    uid_share_%  \n",
              "6      0.456942  \n",
              "12     0.351494  \n",
              "21     0.386643  \n",
              "25     0.386643  \n",
              "16     0.351494  \n",
              "18     0.000000  \n",
              "17     0.316344  \n",
              "2      0.351494  \n",
              "20     0.000000  \n",
              "15     0.281195  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 share (events): 8.07%\n",
            "Top-10 share (unique errors): 3.55%\n"
          ]
        }
      ],
      "source": [
        "def concentration_table(cdf: pd.DataFrame, topk=20):\n",
        "    total_events = len(cdf)\n",
        "    total_uids   = cdf[\"uid\"].nunique()\n",
        "\n",
        "    by_events = cdf[\"prediction\"].value_counts().head(topk).reset_index()\n",
        "    by_events.columns = [\"prediction\", \"collision_events\"]\n",
        "    by_events[\"event_share_%\"] = 100 * by_events[\"collision_events\"] / total_events\n",
        "\n",
        "    by_uids = (cdf.groupby(\"prediction\")[\"uid\"].nunique()\n",
        "               .sort_values(ascending=False).head(topk).reset_index())\n",
        "    by_uids.columns = [\"prediction\", \"unique_error_samples\"]\n",
        "    by_uids[\"uid_share_%\"] = 100 * by_uids[\"unique_error_samples\"] / total_uids\n",
        "\n",
        "    out = by_events.merge(by_uids, on=\"prediction\", how=\"outer\").fillna(0)\n",
        "    return out.sort_values(\"collision_events\", ascending=False), total_events, total_uids\n",
        "\n",
        "for t in [\"sent\", \"word\"]:\n",
        "    cdf = coll[coll[\"task\"] == t].copy()\n",
        "    tab, n_events, n_uids = concentration_table(cdf, topk=20)\n",
        "\n",
        "    print(f\"\\n=== {t.upper()} ===\")\n",
        "    print(f\"collision events={n_events} | unique colliding error samples={n_uids}\")\n",
        "    display(tab.head(10))\n",
        "\n",
        "    top10_event_share = cdf[\"prediction\"].value_counts().head(10).sum() / n_events * 100\n",
        "    top10_uid_share = (cdf.groupby(\"prediction\")[\"uid\"].nunique()\n",
        "                       .sort_values(ascending=False).head(10).sum() / n_uids * 100)\n",
        "    print(f\"Top-10 share (events): {top10_event_share:.2f}%\")\n",
        "    print(f\"Top-10 share (unique errors): {top10_uid_share:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SENT gt_label_count stats for collided predictions ===\n",
            "count    24467.000000\n",
            "mean        16.489271\n",
            "std          5.047093\n",
            "min          1.000000\n",
            "50%         17.000000\n",
            "75%         19.000000\n",
            "90%         23.000000\n",
            "95%         25.000000\n",
            "99%         28.000000\n",
            "max         38.000000\n",
            "Name: gt_label_count, dtype: float64\n",
            "\n",
            "=== WORD gt_label_count stats for collided predictions ===\n",
            "count    41576.000000\n",
            "mean        19.174187\n",
            "std          9.946837\n",
            "min          0.000000\n",
            "50%         18.000000\n",
            "75%         24.000000\n",
            "90%         29.000000\n",
            "95%         37.000000\n",
            "99%         58.000000\n",
            "max         58.000000\n",
            "Name: gt_label_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "label_freq = (df.groupby([\"task\", \"label\"]).size()\n",
        "              .reset_index(name=\"gt_label_count\"))\n",
        "\n",
        "coll_freq = coll.merge(\n",
        "    label_freq,\n",
        "    left_on=[\"task\", \"prediction\"],\n",
        "    right_on=[\"task\", \"label\"],\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_gt\")   # <- important: makes the right-side label \"label_gt\"\n",
        ")\n",
        "\n",
        "# Now drop only the right-side join key (optional)\n",
        "if \"label_gt\" in coll_freq.columns:\n",
        "    coll_freq = coll_freq.drop(columns=[\"label_gt\"])\n",
        "\n",
        "coll_freq[\"gt_label_count\"] = coll_freq[\"gt_label_count\"].fillna(0).astype(int)\n",
        "\n",
        "for t in [\"sent\", \"word\"]:\n",
        "    x = coll_freq[coll_freq[\"task\"] == t][\"gt_label_count\"]\n",
        "    print(f\"\\n=== {t.upper()} gt_label_count stats for collided predictions ===\")\n",
        "    print(x.describe(percentiles=[.5,.75,.9,.95,.99]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['task', 'fold', 'json_path', 'sample_index', 'prediction', 'label', 'levenshtein_distance', 'uid', 'pred_norm', 'lab_norm', 'lev_pred_gt', 'match_fold', 'match_sample_index', 'match_uid', 'match_label', 'match_lab_norm', 'gt_label_count']\n"
          ]
        }
      ],
      "source": [
        "print(coll_freq.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check 2 — Input similarity on curated collision pairs (Notebook implementation)\n",
        "\n",
        "This part depends on access to your IMU JSON files (paths in json_path). The code below is robust to common JSON layouts and implements the “dynamics-based” representation:\n",
        "\n",
        "first-order differences (Δx)\n",
        "\n",
        "inter-channel correlation (on x and Δx)\n",
        "\n",
        "cosine similarity of the resulting feature vectors\n",
        "\n",
        "It outputs:\n",
        "\n",
        "collision_similarity_pairs.csv (per-pair similarity values)\n",
        "\n",
        "collision_similarity_summary.csv (delta + probability > chance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "import yaml\n",
        "\n",
        "def load_cfg(yaml_path: str) -> argparse.Namespace:\n",
        "    with open(yaml_path, \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    return argparse.Namespace(**cfg)\n",
        "\n",
        "CFG_SENT_PATH = \"/home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/configs/test_sent.yaml\"\n",
        "CFG_WORD_PATH = \"/home/woody/iwso/iwso214h/imu-hwr/work/REWI_work/configs/test.yaml\"\n",
        "\n",
        "cfg_sent = load_cfg(CFG_SENT_PATH)\n",
        "cfg_word = load_cfg(CFG_WORD_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ratio_ds sent: 8\n",
            "ratio_ds word: 8\n"
          ]
        }
      ],
      "source": [
        "from rewi.model import build_encoder\n",
        "\n",
        "def encoder_ratio_ds(cfg: argparse.Namespace) -> int:\n",
        "    enc = build_encoder(cfg.num_channel, cfg.arch_en, getattr(cfg, \"len_seq\", 0))\n",
        "    return int(enc.ratio_ds)\n",
        "\n",
        "ratio_sent = encoder_ratio_ds(cfg_sent)\n",
        "ratio_word = encoder_ratio_ds(cfg_word)\n",
        "\n",
        "print(\"ratio_ds sent:\", ratio_sent)\n",
        "print(\"ratio_ds word:\", ratio_word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rewi.dataset import HRDataset\n",
        "\n",
        "DATASET_CACHE = {}\n",
        "\n",
        "def get_val_dataset(task: str, fold: int) -> HRDataset:\n",
        "    key = (task, fold)\n",
        "    if key in DATASET_CACHE:\n",
        "        return DATASET_CACHE[key]\n",
        "\n",
        "    if task == \"sent\":\n",
        "        cfg = cfg_sent\n",
        "        ratio_ds = ratio_sent\n",
        "    elif task == \"word\":\n",
        "        cfg = cfg_word\n",
        "        ratio_ds = ratio_word\n",
        "    else:\n",
        "        raise ValueError(task)\n",
        "\n",
        "    ds = HRDataset(\n",
        "        path_anno=os.path.join(cfg.dir_dataset, \"val.json\"),\n",
        "        categories=cfg.categories,\n",
        "        ratio_ds=ratio_ds,\n",
        "        idx_fold=fold,\n",
        "        len_seq=getattr(cfg, \"len_seq\", 0),\n",
        "        aug=False,\n",
        "        cache=getattr(cfg, \"cache\", False),\n",
        "    )\n",
        "    DATASET_CACHE[key] = ds\n",
        "    return ds\n",
        "\n",
        "def extract_x(item):\n",
        "    # HRDataset returns (seq, label)\n",
        "    x = item[0]\n",
        "    if hasattr(x, \"detach\"):\n",
        "        x = x.detach().cpu().numpy()\n",
        "    x = np.asarray(x)\n",
        "    if x.ndim != 2:\n",
        "        raise ValueError(f\"Expected (T,C), got {x.shape}\")\n",
        "    return x\n",
        "\n",
        "def load_x(task: str, fold: int, sample_index: int) -> np.ndarray:\n",
        "    ds = get_val_dataset(task, fold)\n",
        "    return extract_x(ds[int(sample_index)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "task\n",
            "sent    200\n",
            "word    200\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>fold</th>\n",
              "      <th>sample_index</th>\n",
              "      <th>match_fold</th>\n",
              "      <th>match_sample_index</th>\n",
              "      <th>prediction</th>\n",
              "      <th>label</th>\n",
              "      <th>match_label</th>\n",
              "      <th>lev_pred_gt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1016</td>\n",
              "      <td>0</td>\n",
              "      <td>2443</td>\n",
              "      <td>Souvenir; Andenken</td>\n",
              "      <td>Good morning.</td>\n",
              "      <td>Souvenir; Andenken</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1026</td>\n",
              "      <td>0</td>\n",
              "      <td>1220</td>\n",
              "      <td>fast; annähernd</td>\n",
              "      <td>la reine</td>\n",
              "      <td>fast; annähernd</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1027</td>\n",
              "      <td>1</td>\n",
              "      <td>1156</td>\n",
              "      <td>Und ein Angeber!</td>\n",
              "      <td>un avion</td>\n",
              "      <td>Und ein Angeber!</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1074</td>\n",
              "      <td>0</td>\n",
              "      <td>1895</td>\n",
              "      <td>einschenken; eingießen; schütten</td>\n",
              "      <td>einsteigen; hineingelangen</td>\n",
              "      <td>einschenken; eingießen; schütten</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>1111</td>\n",
              "      <td>Region; Gegend</td>\n",
              "      <td>They're my friends.</td>\n",
              "      <td>Region; Gegend</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>word</td>\n",
              "      <td>0</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2827</td>\n",
              "      <td>Rolltreppe</td>\n",
              "      <td>Rolltreppen</td>\n",
              "      <td>Rolltreppe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>word</td>\n",
              "      <td>0</td>\n",
              "      <td>236</td>\n",
              "      <td>3</td>\n",
              "      <td>1332</td>\n",
              "      <td>Steuer</td>\n",
              "      <td>Staus</td>\n",
              "      <td>Steuer</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>word</td>\n",
              "      <td>0</td>\n",
              "      <td>2364</td>\n",
              "      <td>0</td>\n",
              "      <td>2212</td>\n",
              "      <td>cannot</td>\n",
              "      <td>court</td>\n",
              "      <td>cannot</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>word</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>2880</td>\n",
              "      <td>DVD</td>\n",
              "      <td>DTM</td>\n",
              "      <td>DVD</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>word</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>0</td>\n",
              "      <td>2068</td>\n",
              "      <td>Gefühl</td>\n",
              "      <td>qualitative</td>\n",
              "      <td>Gefühl</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     task  fold  sample_index  match_fold  match_sample_index  \\\n",
              "0    sent     0          1016           0                2443   \n",
              "1    sent     0          1026           0                1220   \n",
              "2    sent     0          1027           1                1156   \n",
              "3    sent     0          1074           0                1895   \n",
              "4    sent     0           108           0                1111   \n",
              "..    ...   ...           ...         ...                 ...   \n",
              "395  word     0           234           0                2827   \n",
              "396  word     0           236           3                1332   \n",
              "397  word     0          2364           0                2212   \n",
              "398  word     0           237           0                2880   \n",
              "399  word     0           240           0                2068   \n",
              "\n",
              "                           prediction                       label  \\\n",
              "0                  Souvenir; Andenken               Good morning.   \n",
              "1                     fast; annähernd                    la reine   \n",
              "2                    Und ein Angeber!                    un avion   \n",
              "3    einschenken; eingießen; schütten  einsteigen; hineingelangen   \n",
              "4                      Region; Gegend         They're my friends.   \n",
              "..                                ...                         ...   \n",
              "395                        Rolltreppe                 Rolltreppen   \n",
              "396                            Steuer                       Staus   \n",
              "397                            cannot                       court   \n",
              "398                               DVD                         DTM   \n",
              "399                            Gefühl                 qualitative   \n",
              "\n",
              "                          match_label  lev_pred_gt  \n",
              "0                  Souvenir; Andenken           14  \n",
              "1                     fast; annähernd           11  \n",
              "2                    Und ein Angeber!           13  \n",
              "3    einschenken; eingießen; schütten           17  \n",
              "4                      Region; Gegend           14  \n",
              "..                                ...          ...  \n",
              "395                        Rolltreppe            1  \n",
              "396                            Steuer            3  \n",
              "397                            cannot            4  \n",
              "398                               DVD            2  \n",
              "399                            Gefühl           11  \n",
              "\n",
              "[400 rows x 9 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# One matched sample per error uid (stable selection of one match per uid)\n",
        "pairs = (coll.sort_values([\"uid\", \"match_uid\"])\n",
        "         .drop_duplicates(subset=[\"uid\"])\n",
        "         .copy())\n",
        "\n",
        "# Diversify within each task: at most 2 per prediction\n",
        "curated = (pairs.groupby([\"task\", \"prediction\"], group_keys=False)\n",
        "           .head(2))\n",
        "\n",
        "curated200 = pd.concat([\n",
        "    curated[curated[\"task\"]==\"sent\"].head(200),\n",
        "    curated[curated[\"task\"]==\"word\"].head(200),\n",
        "], ignore_index=True)\n",
        "\n",
        "\n",
        "print(curated200[\"task\"].value_counts())\n",
        "curated200[[\"task\",\"fold\",\"sample_index\",\"match_fold\",\"match_sample_index\",\n",
        "           \"prediction\",\"label\",\"match_label\",\"lev_pred_gt\"]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>uid</th>\n",
              "      <th>match_uid</th>\n",
              "      <th>prediction</th>\n",
              "      <th>gt_i</th>\n",
              "      <th>gt_j</th>\n",
              "      <th>lev_pred_gt</th>\n",
              "      <th>Ti</th>\n",
              "      <th>Tj</th>\n",
              "      <th>feat_cos_dyn</th>\n",
              "      <th>seq_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>sent</td>\n",
              "      <td>sent|0|2020</td>\n",
              "      <td>sent|0|167</td>\n",
              "      <td>to save</td>\n",
              "      <td>to add</td>\n",
              "      <td>to save</td>\n",
              "      <td>3</td>\n",
              "      <td>436</td>\n",
              "      <td>256</td>\n",
              "      <td>0.512806</td>\n",
              "      <td>0.189861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>sent</td>\n",
              "      <td>sent|0|2902</td>\n",
              "      <td>sent|1|159</td>\n",
              "      <td>to put through</td>\n",
              "      <td>to put up, put up</td>\n",
              "      <td>to put through</td>\n",
              "      <td>9</td>\n",
              "      <td>754</td>\n",
              "      <td>838</td>\n",
              "      <td>0.902871</td>\n",
              "      <td>0.181181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>sent</td>\n",
              "      <td>sent|0|2663</td>\n",
              "      <td>sent|0|110</td>\n",
              "      <td>to ask</td>\n",
              "      <td>to cost</td>\n",
              "      <td>to ask</td>\n",
              "      <td>3</td>\n",
              "      <td>231</td>\n",
              "      <td>170</td>\n",
              "      <td>0.874548</td>\n",
              "      <td>0.177116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>sent</td>\n",
              "      <td>sent|0|127</td>\n",
              "      <td>sent|0|140</td>\n",
              "      <td>private detective</td>\n",
              "      <td>point of view</td>\n",
              "      <td>private detective</td>\n",
              "      <td>12</td>\n",
              "      <td>334</td>\n",
              "      <td>576</td>\n",
              "      <td>0.950929</td>\n",
              "      <td>0.164751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>sent</td>\n",
              "      <td>sent|0|1393</td>\n",
              "      <td>sent|0|1853</td>\n",
              "      <td>als Nächstes</td>\n",
              "      <td>alarm clock</td>\n",
              "      <td>als Nächstes</td>\n",
              "      <td>9</td>\n",
              "      <td>356</td>\n",
              "      <td>440</td>\n",
              "      <td>0.870247</td>\n",
              "      <td>0.163395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>word</td>\n",
              "      <td>word|0|1543</td>\n",
              "      <td>word|0|137</td>\n",
              "      <td>wichtig</td>\n",
              "      <td>dreckig</td>\n",
              "      <td>wichtig</td>\n",
              "      <td>5</td>\n",
              "      <td>695</td>\n",
              "      <td>196</td>\n",
              "      <td>0.791522</td>\n",
              "      <td>-0.124254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>word</td>\n",
              "      <td>word|0|2098</td>\n",
              "      <td>word|0|1942</td>\n",
              "      <td>Weg</td>\n",
              "      <td>cent</td>\n",
              "      <td>Weg</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>118</td>\n",
              "      <td>0.535442</td>\n",
              "      <td>-0.130057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>word</td>\n",
              "      <td>word|0|1704</td>\n",
              "      <td>word|0|71</td>\n",
              "      <td>nein</td>\n",
              "      <td>voir</td>\n",
              "      <td>nein</td>\n",
              "      <td>3</td>\n",
              "      <td>242</td>\n",
              "      <td>120</td>\n",
              "      <td>0.765943</td>\n",
              "      <td>-0.131371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>word</td>\n",
              "      <td>word|0|1062</td>\n",
              "      <td>word|0|868</td>\n",
              "      <td>drücken</td>\n",
              "      <td>drucken</td>\n",
              "      <td>drücken</td>\n",
              "      <td>1</td>\n",
              "      <td>466</td>\n",
              "      <td>551</td>\n",
              "      <td>0.753236</td>\n",
              "      <td>-0.150784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>word</td>\n",
              "      <td>word|0|1779</td>\n",
              "      <td>word|0|3101</td>\n",
              "      <td>Hauptstadt</td>\n",
              "      <td>Handlungsspielräume</td>\n",
              "      <td>Hauptstadt</td>\n",
              "      <td>15</td>\n",
              "      <td>1022</td>\n",
              "      <td>497</td>\n",
              "      <td>0.863037</td>\n",
              "      <td>-0.161111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     task          uid    match_uid         prediction                 gt_i  \\\n",
              "47   sent  sent|0|2020   sent|0|167            to save               to add   \n",
              "130  sent  sent|0|2902   sent|1|159     to put through    to put up, put up   \n",
              "120  sent  sent|0|2663   sent|0|110             to ask              to cost   \n",
              "15   sent   sent|0|127   sent|0|140  private detective        point of view   \n",
              "19   sent  sent|0|1393  sent|0|1853       als Nächstes          alarm clock   \n",
              "..    ...          ...          ...                ...                  ...   \n",
              "269  word  word|0|1543   word|0|137            wichtig              dreckig   \n",
              "363  word  word|0|2098  word|0|1942                Weg                 cent   \n",
              "318  word  word|0|1704    word|0|71               nein                 voir   \n",
              "211  word  word|0|1062   word|0|868            drücken              drucken   \n",
              "328  word  word|0|1779  word|0|3101         Hauptstadt  Handlungsspielräume   \n",
              "\n",
              "                  gt_j  lev_pred_gt    Ti   Tj  feat_cos_dyn   seq_cos  \n",
              "47             to save            3   436  256      0.512806  0.189861  \n",
              "130     to put through            9   754  838      0.902871  0.181181  \n",
              "120             to ask            3   231  170      0.874548  0.177116  \n",
              "15   private detective           12   334  576      0.950929  0.164751  \n",
              "19        als Nächstes            9   356  440      0.870247  0.163395  \n",
              "..                 ...          ...   ...  ...           ...       ...  \n",
              "269            wichtig            5   695  196      0.791522 -0.124254  \n",
              "363                Weg            3   130  118      0.535442 -0.130057  \n",
              "318               nein            3   242  120      0.765943 -0.131371  \n",
              "211            drücken            1   466  551      0.753236 -0.150784  \n",
              "328         Hauptstadt           15  1022  497      0.863037 -0.161111  \n",
              "\n",
              "[400 rows x 11 columns]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def resample_to_fixed_length(x: np.ndarray, L: int = 200) -> np.ndarray:\n",
        "    T, C = x.shape\n",
        "    if T == L:\n",
        "        return x\n",
        "    t_old = np.linspace(0, 1, T)\n",
        "    t_new = np.linspace(0, 1, L)\n",
        "    out = np.zeros((L, C), dtype=float)\n",
        "    for c in range(C):\n",
        "        out[:, c] = np.interp(t_new, t_old, x[:, c])\n",
        "    return out\n",
        "\n",
        "def zscore(x: np.ndarray) -> np.ndarray:\n",
        "    mu = x.mean(axis=0, keepdims=True)\n",
        "    sd = x.std(axis=0, keepdims=True) + 1e-8\n",
        "    return (x - mu) / sd\n",
        "\n",
        "def cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    a = a.astype(float); b = b.astype(float)\n",
        "    return float(np.dot(a, b) / ((np.linalg.norm(a)+1e-12) * (np.linalg.norm(b)+1e-12)))\n",
        "\n",
        "def feature_vector(x: np.ndarray) -> np.ndarray:\n",
        "    mu  = x.mean(axis=0)\n",
        "    std = x.std(axis=0)\n",
        "    mn  = x.min(axis=0)\n",
        "    mx  = x.max(axis=0)\n",
        "    eng = (x**2).mean(axis=0)\n",
        "    return np.concatenate([mu, std, mn, mx, eng], axis=0)\n",
        "\n",
        "def dyn_feature_vector(x: np.ndarray) -> np.ndarray:\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    dx = np.diff(x, axis=0)  # dynamics\n",
        "\n",
        "    dx_mu  = dx.mean(axis=0)\n",
        "    dx_std = dx.std(axis=0)\n",
        "    dx_eng = (dx**2).mean(axis=0)\n",
        "\n",
        "    # channel correlation structure\n",
        "    C = x.shape[1]\n",
        "    corr = np.corrcoef(x.T)\n",
        "    triu = corr[np.triu_indices(C, k=1)]\n",
        "\n",
        "    return np.concatenate([dx_mu, dx_std, dx_eng, triu], axis=0)\n",
        "\n",
        "results = []\n",
        "for r in curated200.itertuples(index=False):\n",
        "    xi = load_x(r.task, int(r.fold), int(r.sample_index))\n",
        "    xj = load_x(r.task, int(r.match_fold), int(r.match_sample_index))\n",
        "\n",
        "    # Dynamics-based similarity (meaningful after per-sample normalization)\n",
        "    feat_cos_dyn = cosine(dyn_feature_vector(xi), dyn_feature_vector(xj))\n",
        "\n",
        "    # Sequence similarity (time-ordered, crude baseline)\n",
        "    xi_r = resample_to_fixed_length(zscore(xi), L=200).reshape(-1)\n",
        "    xj_r = resample_to_fixed_length(zscore(xj), L=200).reshape(-1)\n",
        "    seq_cos = cosine(xi_r, xj_r)\n",
        "\n",
        "    results.append({\n",
        "        \"task\": r.task,\n",
        "        \"uid\": r.uid,\n",
        "        \"match_uid\": r.match_uid,\n",
        "        \"prediction\": r.prediction,\n",
        "        \"gt_i\": r.label,\n",
        "        \"gt_j\": r.match_label,\n",
        "        \"lev_pred_gt\": int(r.lev_pred_gt),\n",
        "        \"Ti\": xi.shape[0], \"Tj\": xj.shape[0],\n",
        "        \"feat_cos_dyn\": feat_cos_dyn,\n",
        "        \"seq_cos\": seq_cos,\n",
        "    })\n",
        "\n",
        "sim_df = pd.DataFrame(results).sort_values([\"task\",\"seq_cos\"], ascending=[True, False])\n",
        "sim_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">feat_cos_dyn</th>\n",
              "      <th colspan=\"8\" halign=\"left\">seq_cos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>200.0</td>\n",
              "      <td>0.700605</td>\n",
              "      <td>0.162864</td>\n",
              "      <td>0.098255</td>\n",
              "      <td>0.601864</td>\n",
              "      <td>0.734659</td>\n",
              "      <td>0.816192</td>\n",
              "      <td>0.950929</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.020515</td>\n",
              "      <td>0.065303</td>\n",
              "      <td>-0.160135</td>\n",
              "      <td>-0.022135</td>\n",
              "      <td>0.017278</td>\n",
              "      <td>0.062851</td>\n",
              "      <td>0.189861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>200.0</td>\n",
              "      <td>0.707805</td>\n",
              "      <td>0.152743</td>\n",
              "      <td>0.114101</td>\n",
              "      <td>0.647254</td>\n",
              "      <td>0.749687</td>\n",
              "      <td>0.804714</td>\n",
              "      <td>0.934405</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.020934</td>\n",
              "      <td>0.087505</td>\n",
              "      <td>-0.161111</td>\n",
              "      <td>-0.025709</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.059482</td>\n",
              "      <td>0.352767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feat_cos_dyn                                                              \\\n",
              "            count      mean       std       min       25%       50%       75%   \n",
              "task                                                                            \n",
              "sent        200.0  0.700605  0.162864  0.098255  0.601864  0.734659  0.816192   \n",
              "word        200.0  0.707805  0.152743  0.114101  0.647254  0.749687  0.804714   \n",
              "\n",
              "               seq_cos                                                    \\\n",
              "           max   count      mean       std       min       25%       50%   \n",
              "task                                                                       \n",
              "sent  0.950929   200.0  0.020515  0.065303 -0.160135 -0.022135  0.017278   \n",
              "word  0.934405   200.0  0.020934  0.087505 -0.161111 -0.025709  0.005775   \n",
              "\n",
              "                          \n",
              "           75%       max  \n",
              "task                      \n",
              "sent  0.062851  0.189861  \n",
              "word  0.059482  0.352767  "
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim_df.groupby(\"task\")[[\"feat_cos_dyn\",\"seq_cos\"]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sent fold 0 len(ds)= 4188 max sample_index in collisions= 4172\n",
            "sent fold 1 len(ds)= 3684 max sample_index in collisions= 3681\n",
            "sent fold 2 len(ds)= 4416 max sample_index in collisions= 4415\n",
            "sent fold 3 len(ds)= 3871 max sample_index in collisions= 3867\n",
            "sent fold 4 len(ds)= 4480 max sample_index in collisions= 4479\n",
            "word fold 0 len(ds)= 4734 max sample_index in collisions= 4731\n",
            "word fold 1 len(ds)= 5002 max sample_index in collisions= 4995\n",
            "word fold 2 len(ds)= 4694 max sample_index in collisions= 4669\n",
            "word fold 3 len(ds)= 4656 max sample_index in collisions= 4655\n",
            "word fold 4 len(ds)= 5077 max sample_index in collisions= 5075\n"
          ]
        }
      ],
      "source": [
        "for t in [\"sent\",\"word\"]:\n",
        "    sub = coll[coll[\"task\"] == t]\n",
        "    for fold in sorted(sub[\"fold\"].unique())[:5]:\n",
        "        ds = get_val_dataset(t, int(fold))\n",
        "        mx = sub[sub[\"fold\"] == fold][\"sample_index\"].max()\n",
        "        print(t, \"fold\", fold, \"len(ds)=\", len(ds), \"max sample_index in collisions=\", mx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">sim_collision</th>\n",
              "      <th colspan=\"5\" halign=\"left\">sim_random</th>\n",
              "      <th colspan=\"8\" halign=\"left\">delta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>...</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>200.0</td>\n",
              "      <td>0.700605</td>\n",
              "      <td>0.162864</td>\n",
              "      <td>0.098255</td>\n",
              "      <td>0.601864</td>\n",
              "      <td>0.734659</td>\n",
              "      <td>0.816192</td>\n",
              "      <td>0.950929</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.689004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.809876</td>\n",
              "      <td>0.935645</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.011601</td>\n",
              "      <td>0.174156</td>\n",
              "      <td>-0.534280</td>\n",
              "      <td>-0.083545</td>\n",
              "      <td>0.008773</td>\n",
              "      <td>0.107422</td>\n",
              "      <td>0.600210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>200.0</td>\n",
              "      <td>0.707805</td>\n",
              "      <td>0.152743</td>\n",
              "      <td>0.114101</td>\n",
              "      <td>0.647254</td>\n",
              "      <td>0.749687</td>\n",
              "      <td>0.804714</td>\n",
              "      <td>0.934405</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.709889</td>\n",
              "      <td>...</td>\n",
              "      <td>0.819757</td>\n",
              "      <td>0.935397</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-0.002084</td>\n",
              "      <td>0.111945</td>\n",
              "      <td>-0.441257</td>\n",
              "      <td>-0.066629</td>\n",
              "      <td>-0.004052</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>0.306242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sim_collision                                                    \\\n",
              "             count      mean       std       min       25%       50%   \n",
              "task                                                                   \n",
              "sent         200.0  0.700605  0.162864  0.098255  0.601864  0.734659   \n",
              "word         200.0  0.707805  0.152743  0.114101  0.647254  0.749687   \n",
              "\n",
              "                         sim_random            ...                      delta  \\\n",
              "           75%       max      count      mean  ...       75%       max  count   \n",
              "task                                           ...                              \n",
              "sent  0.816192  0.950929      200.0  0.689004  ...  0.809876  0.935645  200.0   \n",
              "word  0.804714  0.934405      200.0  0.709889  ...  0.819757  0.935397  200.0   \n",
              "\n",
              "                                                                            \n",
              "          mean       std       min       25%       50%       75%       max  \n",
              "task                                                                        \n",
              "sent  0.011601  0.174156 -0.534280 -0.083545  0.008773  0.107422  0.600210  \n",
              "word -0.002084  0.111945 -0.441257 -0.066629 -0.004052  0.063119  0.306242  \n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "P(sim_collision > sim_random) by task:\n",
            "task\n",
            "sent    0.535\n",
            "word    0.490\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1849888/2998941465.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  print(base_df.groupby(\"task\").apply(lambda g: (g[\"delta\"] > 0).mean()))\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "def sample_random_idx(task: str, fold: int, avoid_idx: int) -> int:\n",
        "    ds = get_val_dataset(task, fold)\n",
        "    n = len(ds)\n",
        "    while True:\n",
        "        k = random.randint(0, n - 1)\n",
        "        if k != avoid_idx:\n",
        "            return k\n",
        "\n",
        "baseline_rows = []\n",
        "for r in curated200.itertuples(index=False):\n",
        "    task = r.task\n",
        "    fold = int(r.fold)\n",
        "    i_idx = int(r.sample_index)\n",
        "\n",
        "    xi = load_x(task, fold, i_idx)\n",
        "\n",
        "    # collision match\n",
        "    xj = load_x(task, int(r.match_fold), int(r.match_sample_index))\n",
        "    sim_collision = cosine(dyn_feature_vector(xi), dyn_feature_vector(xj))\n",
        "\n",
        "    # random match (same fold/task)\n",
        "    k_idx = sample_random_idx(task, fold, i_idx)\n",
        "    xk = load_x(task, fold, k_idx)\n",
        "    sim_random = cosine(dyn_feature_vector(xi), dyn_feature_vector(xk))\n",
        "\n",
        "    baseline_rows.append({\n",
        "        \"task\": task,\n",
        "        \"uid\": r.uid,\n",
        "        \"prediction\": r.prediction,\n",
        "        \"sim_collision\": sim_collision,\n",
        "        \"sim_random\": sim_random,\n",
        "        \"delta\": sim_collision - sim_random\n",
        "    })\n",
        "\n",
        "base_df = pd.DataFrame(baseline_rows)\n",
        "display(base_df.groupby(\"task\")[[\"sim_collision\",\"sim_random\",\"delta\"]].describe())\n",
        "\n",
        "# How often is collision similarity higher than random?\n",
        "print(\"\\nP(sim_collision > sim_random) by task:\")\n",
        "print(base_df.groupby(\"task\").apply(lambda g: (g[\"delta\"] > 0).mean()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      mean_collision  mean_random  mean_delta  median_delta  p_collision_gt_random  std_delta    n\n",
            "task                                                                                              \n",
            "sent        0.700605     0.689004    0.011601      0.008773                  0.535   0.174156  200\n",
            "word        0.707805     0.709889   -0.002084     -0.004052                  0.490   0.111945  200\n"
          ]
        }
      ],
      "source": [
        "summary = base_df.groupby(\"task\").agg(\n",
        "    mean_collision=(\"sim_collision\", \"mean\"),\n",
        "    mean_random=(\"sim_random\", \"mean\"),\n",
        "    mean_delta=(\"delta\", \"mean\"),\n",
        "    median_delta=(\"delta\", \"median\"),\n",
        "    p_collision_gt_random=(\"delta\", lambda s: (s > 0).mean()),\n",
        "    std_delta=(\"delta\", \"std\"),\n",
        "    n=(\"delta\", \"size\"),\n",
        ")\n",
        "print(summary.to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: ./collision_redo/baseline_similarity_summary_new.csv\n"
          ]
        }
      ],
      "source": [
        "desc = base_df.groupby(\"task\")[[\"sim_collision\",\"sim_random\",\"delta\"]].describe()\n",
        "out_path = \"./collision_redo/baseline_similarity_summary_new.csv\"\n",
        "desc.to_csv(out_path)\n",
        "print(\"Wrote:\", out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check 3: Writer based analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coll_freq rows (event-weighted): 66043\n",
            "coll_freq rows (UID-weighted): 4557\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>match_uid</th>\n",
              "      <th>task</th>\n",
              "      <th>fold</th>\n",
              "      <th>sample_index</th>\n",
              "      <th>prediction</th>\n",
              "      <th>label</th>\n",
              "      <th>match_label</th>\n",
              "      <th>pred_norm</th>\n",
              "      <th>gt_label_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sent|0|21</td>\n",
              "      <td>sent|0|1209</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich freuen auf</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sent|0|21</td>\n",
              "      <td>sent|0|3282</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich freuen auf</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sent|0|21</td>\n",
              "      <td>sent|0|3539</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich freuen auf</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>sich handeln um</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         uid    match_uid  task  fold  sample_index       prediction  \\\n",
              "0  sent|0|21  sent|0|1209  sent     0            21  sich handeln um   \n",
              "1  sent|0|21  sent|0|3282  sent     0            21  sich handeln um   \n",
              "2  sent|0|21  sent|0|3539  sent     0            21  sich handeln um   \n",
              "\n",
              "             label      match_label        pred_norm  gt_label_count  \n",
              "0  sich freuen auf  sich handeln um  sich handeln um              19  \n",
              "1  sich freuen auf  sich handeln um  sich handeln um              19  \n",
              "2  sich freuen auf  sich handeln um  sich handeln um              19  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>match_uid</th>\n",
              "      <th>task</th>\n",
              "      <th>fold</th>\n",
              "      <th>sample_index</th>\n",
              "      <th>prediction</th>\n",
              "      <th>label</th>\n",
              "      <th>match_label</th>\n",
              "      <th>pred_norm</th>\n",
              "      <th>gt_label_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>sent|0|1016</td>\n",
              "      <td>sent|0|2443</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1016</td>\n",
              "      <td>Souvenir; Andenken</td>\n",
              "      <td>Good morning.</td>\n",
              "      <td>Souvenir; Andenken</td>\n",
              "      <td>Souvenir; Andenken</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>sent|0|1026</td>\n",
              "      <td>sent|0|1220</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1026</td>\n",
              "      <td>fast; annähernd</td>\n",
              "      <td>la reine</td>\n",
              "      <td>fast; annähernd</td>\n",
              "      <td>fast; annähernd</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>sent|0|1027</td>\n",
              "      <td>sent|1|1156</td>\n",
              "      <td>sent</td>\n",
              "      <td>0</td>\n",
              "      <td>1027</td>\n",
              "      <td>Und ein Angeber!</td>\n",
              "      <td>un avion</td>\n",
              "      <td>Und ein Angeber!</td>\n",
              "      <td>Und ein Angeber!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              uid    match_uid  task  fold  sample_index          prediction  \\\n",
              "1006  sent|0|1016  sent|0|2443  sent     0          1016  Souvenir; Andenken   \n",
              "1018  sent|0|1026  sent|0|1220  sent     0          1026     fast; annähernd   \n",
              "1030  sent|0|1027  sent|1|1156  sent     0          1027    Und ein Angeber!   \n",
              "\n",
              "              label         match_label           pred_norm  gt_label_count  \n",
              "1006  Good morning.  Souvenir; Andenken  Souvenir; Andenken               0  \n",
              "1018       la reine     fast; annähernd     fast; annähernd              12  \n",
              "1030       un avion    Und ein Angeber!    Und ein Angeber!               0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Minimal normalization used in your collision analysis (match what you used earlier)\n",
        "_WS_RE = re.compile(r\"\\s+\")\n",
        "def norm_text(s):\n",
        "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
        "        return \"\"\n",
        "    s = str(s).strip()\n",
        "    return _WS_RE.sub(\" \", s)\n",
        "\n",
        "# Ensure df has uid\n",
        "if \"uid\" not in df.columns:\n",
        "    df[\"uid\"] = df.apply(lambda r: f\"{r['task']}|{int(r['fold'])}|{int(r['sample_index'])}\", axis=1)\n",
        "\n",
        "# Make sure df has normalized label for counts\n",
        "if \"lab_norm\" not in df.columns:\n",
        "    df[\"lab_norm\"] = df[\"label\"].map(norm_text)\n",
        "\n",
        "# Build per-task ground-truth label frequency\n",
        "gt_counts = {t: g[\"lab_norm\"].value_counts() for t, g in df.groupby(\"task\")}\n",
        "\n",
        "# --- coll_freq: event-weighted (one row per collision event) ---\n",
        "# coll_out should already have uid + match_uid; add task/fold/sample_index by joining to df if needed.\n",
        "base_cols = [\"uid\", \"match_uid\"]\n",
        "missing_cols = [c for c in base_cols if c not in coll_out.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"coll_out missing required columns: {missing_cols}\")\n",
        "\n",
        "# Attach metadata for the error uid (i)\n",
        "meta_i = df[[\"uid\", \"task\", \"fold\", \"sample_index\", \"prediction\", \"label\"]].copy()\n",
        "meta_i = meta_i.rename(columns={\n",
        "    \"task\": \"task\",\n",
        "    \"fold\": \"fold\",\n",
        "    \"sample_index\": \"sample_index\",\n",
        "    \"prediction\": \"prediction\",\n",
        "    \"label\": \"label\",\n",
        "})\n",
        "\n",
        "# Attach matched label for the match uid (j)\n",
        "meta_j = df[[\"uid\", \"label\"]].copy().rename(columns={\"uid\": \"match_uid\", \"label\": \"match_label\"})\n",
        "\n",
        "coll_freq = (\n",
        "    coll_out[[\"uid\", \"match_uid\"]]\n",
        "    .merge(meta_i, on=\"uid\", how=\"left\")\n",
        "    .merge(meta_j, on=\"match_uid\", how=\"left\")\n",
        ")\n",
        "\n",
        "# Add gt_label_count for the collided prediction (per task)\n",
        "coll_freq[\"pred_norm\"] = coll_freq[\"prediction\"].map(norm_text)\n",
        "coll_freq[\"gt_label_count\"] = [\n",
        "    int(gt_counts[t].get(pn, 0)) if pd.notna(t) else 0\n",
        "    for t, pn in zip(coll_freq[\"task\"], coll_freq[\"pred_norm\"])\n",
        "]\n",
        "\n",
        "# --- uid_level: UID-weighted (one row per colliding error uid) ---\n",
        "uid_level = (\n",
        "    coll_freq.sort_values([\"uid\", \"match_uid\"])\n",
        "             .drop_duplicates(subset=[\"uid\"])\n",
        "             .copy()\n",
        ")\n",
        "\n",
        "print(\"coll_freq rows (event-weighted):\", len(coll_freq))\n",
        "print(\"coll_freq rows (UID-weighted):\", len(uid_level))\n",
        "display(coll_freq.head(3))\n",
        "display(uid_level.head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "writer_lookup entries: 44802\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_writer_lookup(dir_dataset: str, task_name: str) -> dict:\n",
        "    \"\"\"\n",
        "    Returns dict keyed by (task, fold, sample_index) -> id_writer\n",
        "    \"\"\"\n",
        "    path_val = os.path.join(dir_dataset, \"val.json\")\n",
        "    with open(path_val, \"r\") as f:\n",
        "        ann = json.load(f)\n",
        "\n",
        "    lookup = {}\n",
        "    folds = ann[\"annotations\"].keys()\n",
        "    for fold_str in folds:\n",
        "        items = ann[\"annotations\"][fold_str]\n",
        "        for idx, a in enumerate(items):\n",
        "            # expecting a[\"id_writer\"] exists\n",
        "            lookup[(task_name, int(fold_str), int(idx))] = a.get(\"id_writer\", None)\n",
        "    return lookup\n",
        "\n",
        "writer_lookup = {}\n",
        "writer_lookup.update(build_writer_lookup(cfg_sent.dir_dataset, \"sent\"))\n",
        "writer_lookup.update(build_writer_lookup(cfg_word.dir_dataset, \"word\"))\n",
        "\n",
        "print(\"writer_lookup entries:\", len(writer_lookup))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('sent', 0, 0) -> bu/7A0aK\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "k = (\"sent\", 0, 0)\n",
        "print(k, \"->\", writer_lookup.get(k))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing writer fraction: 0.0000\n",
            "0    bu/7A0aK\n",
            "1    bu/7A0aK\n",
            "2    bu/7A0aK\n",
            "3    bu/7A0aK\n",
            "4    bu/7A0aK\n",
            "Name: id_writer, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df_w = df.copy()\n",
        "df_w[\"id_writer\"] = [\n",
        "    writer_lookup.get((r.task, int(r.fold), int(r.sample_index)), None)\n",
        "    for r in df_w.itertuples(index=False)\n",
        "]\n",
        "\n",
        "missing = df_w[\"id_writer\"].isna().mean()\n",
        "print(f\"Missing writer fraction: {missing:.4f}\")\n",
        "print(df_w[\"id_writer\"].dropna().astype(str).head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coll_freq_w missing writer: 0.0\n",
            "uid_level_w missing writer: 0.0\n"
          ]
        }
      ],
      "source": [
        "coll_freq_w = coll_freq.copy()\n",
        "coll_freq_w[\"id_writer\"] = [\n",
        "    writer_lookup.get((r.task, int(r.fold), int(r.sample_index)), None)\n",
        "    for r in coll_freq_w.itertuples(index=False)\n",
        "]\n",
        "\n",
        "uid_level_w = uid_level.copy()\n",
        "uid_level_w[\"id_writer\"] = [\n",
        "    writer_lookup.get((r.task, int(r.fold), int(r.sample_index)), None)\n",
        "    for r in uid_level_w.itertuples(index=False)\n",
        "]\n",
        "\n",
        "print(\"coll_freq_w missing writer:\", coll_freq_w[\"id_writer\"].isna().mean())\n",
        "print(\"uid_level_w missing writer:\", uid_level_w[\"id_writer\"].isna().mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>id_writer</th>\n",
              "      <th>n_samples</th>\n",
              "      <th>n_errors</th>\n",
              "      <th>n_collision_uids</th>\n",
              "      <th>median_gt_label_count</th>\n",
              "      <th>p90_gt_label_count</th>\n",
              "      <th>n_collision_events</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>collision_rate</th>\n",
              "      <th>collision_given_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>sent</td>\n",
              "      <td>ZbuF!g6b</td>\n",
              "      <td>73</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>sent</td>\n",
              "      <td>28KQnY]1</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>sent</td>\n",
              "      <td>R8qJ5QkV</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.048387</td>\n",
              "      <td>0.048387</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>sent</td>\n",
              "      <td>§A§=?Vw!</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0.016393</td>\n",
              "      <td>0.016393</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>sent</td>\n",
              "      <td>4k/+bh9§</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>sent</td>\n",
              "      <td>47HF=)!p</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.4</td>\n",
              "      <td>32</td>\n",
              "      <td>0.033898</td>\n",
              "      <td>0.033898</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>sent</td>\n",
              "      <td>MSkMRb93</td>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>65</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>sent</td>\n",
              "      <td>8hke§sGT</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.017544</td>\n",
              "      <td>0.017544</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sent</td>\n",
              "      <td>&amp;,![]z5w</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>sent</td>\n",
              "      <td>2#4[A2RD</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.6</td>\n",
              "      <td>40</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>sent</td>\n",
              "      <td>4L[4nABk</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.8</td>\n",
              "      <td>32</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>sent</td>\n",
              "      <td>N0wfwRcs</td>\n",
              "      <td>56</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.4</td>\n",
              "      <td>132</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>sent</td>\n",
              "      <td>[HmvhNvH</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>41</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>sent</td>\n",
              "      <td>kTY,-AM)</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.6</td>\n",
              "      <td>47</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>sent</td>\n",
              "      <td>=k_u§128</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>sent</td>\n",
              "      <td>]Q$Hzvop</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sent</td>\n",
              "      <td>#Na7q!m]</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>sent</td>\n",
              "      <td>y!yUE6k2</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>sent</td>\n",
              "      <td>5we_ZrYR</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>sent</td>\n",
              "      <td>j/[kxs9s</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     task id_writer  n_samples  n_errors  n_collision_uids  \\\n",
              "292  sent  ZbuF!g6b         73         4                 4   \n",
              "85   sent  28KQnY]1         64         1                 1   \n",
              "253  sent  R8qJ5QkV         62         3                 3   \n",
              "451  sent  §A§=?Vw!         61         1                 1   \n",
              "98   sent  4k/+bh9§         60         1                 1   \n",
              "93   sent  47HF=)!p         59         2                 2   \n",
              "227  sent  MSkMRb93         58         4                 4   \n",
              "126  sent  8hke§sGT         57         1                 1   \n",
              "14   sent  &,![]z5w         56         1                 1   \n",
              "82   sent  2#4[A2RD         56         2                 2   \n",
              "95   sent  4L[4nABk         56         2                 2   \n",
              "233  sent  N0wfwRcs         56         8                 8   \n",
              "299  sent  [HmvhNvH         56         3                 3   \n",
              "370  sent  kTY,-AM)         56         3                 3   \n",
              "135  sent  =k_u§128         54         1                 1   \n",
              "304  sent  ]Q$Hzvop         54         1                 1   \n",
              "4    sent  #Na7q!m]         53         1                 1   \n",
              "433  sent  y!yUE6k2         52         1                 1   \n",
              "108  sent  5we_ZrYR         51         1                 1   \n",
              "363  sent  j/[kxs9s         51         1                 1   \n",
              "\n",
              "     median_gt_label_count  p90_gt_label_count  n_collision_events  \\\n",
              "292                    7.0                14.0                  51   \n",
              "85                     0.0                 0.0                  17   \n",
              "253                    0.0                11.2                  50   \n",
              "451                    0.0                 0.0                  18   \n",
              "98                     0.0                 0.0                  12   \n",
              "93                    16.0                18.4                  32   \n",
              "227                    0.0                14.7                  65   \n",
              "126                   15.0                15.0                  15   \n",
              "14                     0.0                 0.0                  12   \n",
              "82                    20.0                21.6                  40   \n",
              "95                    16.0                16.8                  32   \n",
              "233                   15.0                20.4                 132   \n",
              "299                    0.0                 8.8                  41   \n",
              "370                   15.0                16.6                  47   \n",
              "135                    0.0                 0.0                   9   \n",
              "304                    0.0                 0.0                  17   \n",
              "4                      0.0                 0.0                  17   \n",
              "433                   13.0                13.0                  13   \n",
              "108                   23.0                23.0                  23   \n",
              "363                   12.0                12.0                  12   \n",
              "\n",
              "     error_rate  collision_rate  collision_given_error  \n",
              "292    0.054795        0.054795                    1.0  \n",
              "85     0.015625        0.015625                    1.0  \n",
              "253    0.048387        0.048387                    1.0  \n",
              "451    0.016393        0.016393                    1.0  \n",
              "98     0.016667        0.016667                    1.0  \n",
              "93     0.033898        0.033898                    1.0  \n",
              "227    0.068966        0.068966                    1.0  \n",
              "126    0.017544        0.017544                    1.0  \n",
              "14     0.017857        0.017857                    1.0  \n",
              "82     0.035714        0.035714                    1.0  \n",
              "95     0.035714        0.035714                    1.0  \n",
              "233    0.142857        0.142857                    1.0  \n",
              "299    0.053571        0.053571                    1.0  \n",
              "370    0.053571        0.053571                    1.0  \n",
              "135    0.018519        0.018519                    1.0  \n",
              "304    0.018519        0.018519                    1.0  \n",
              "4      0.018868        0.018868                    1.0  \n",
              "433    0.019231        0.019231                    1.0  \n",
              "108    0.019608        0.019608                    1.0  \n",
              "363    0.019608        0.019608                    1.0  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# total samples per writer\n",
        "totals = (df_w.groupby([\"task\",\"id_writer\"])\n",
        "          .agg(n_samples=(\"uid\",\"size\"),\n",
        "               n_errors=(\"levenshtein_distance\", lambda s: int((s > 0).sum())))\n",
        "          .reset_index())\n",
        "\n",
        "# colliding uids per writer (UID-weighted)\n",
        "coll_uids = (uid_level_w.groupby([\"task\",\"id_writer\"])\n",
        "             .agg(n_collision_uids=(\"uid\",\"nunique\"),\n",
        "                  median_gt_label_count=(\"gt_label_count\",\"median\"),\n",
        "                  p90_gt_label_count=(\"gt_label_count\", lambda s: float(s.quantile(0.90))))\n",
        "             .reset_index())\n",
        "\n",
        "# collision events per writer (event-weighted)\n",
        "coll_events = (coll_freq_w.groupby([\"task\",\"id_writer\"])\n",
        "               .agg(n_collision_events=(\"uid\",\"size\"))\n",
        "               .reset_index())\n",
        "\n",
        "writer_stats = (totals.merge(coll_uids, on=[\"task\",\"id_writer\"], how=\"left\")\n",
        "                      .merge(coll_events, on=[\"task\",\"id_writer\"], how=\"left\"))\n",
        "\n",
        "writer_stats[[\"n_collision_uids\",\"n_collision_events\"]] = writer_stats[[\"n_collision_uids\",\"n_collision_events\"]].fillna(0).astype(int)\n",
        "\n",
        "# rates\n",
        "writer_stats[\"error_rate\"] = writer_stats[\"n_errors\"] / writer_stats[\"n_samples\"]\n",
        "writer_stats[\"collision_rate\"] = writer_stats[\"n_collision_uids\"] / writer_stats[\"n_samples\"]\n",
        "writer_stats[\"collision_given_error\"] = writer_stats[\"n_collision_uids\"] / writer_stats[\"n_errors\"].replace(0, np.nan)\n",
        "\n",
        "# sort for inspection\n",
        "writer_stats = writer_stats.sort_values([\"task\",\"collision_given_error\",\"n_samples\"], ascending=[True, False, False])\n",
        "\n",
        "writer_stats.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>top_k</th>\n",
              "      <th>collision_share_%</th>\n",
              "      <th>sample_share_%</th>\n",
              "      <th>lift</th>\n",
              "      <th>collision_given_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sent</td>\n",
              "      <td>5</td>\n",
              "      <td>8.644860</td>\n",
              "      <td>2.500121</td>\n",
              "      <td>3.457776</td>\n",
              "      <td>0.494983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sent</td>\n",
              "      <td>10</td>\n",
              "      <td>14.427570</td>\n",
              "      <td>4.820970</td>\n",
              "      <td>2.992670</td>\n",
              "      <td>0.542857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sent</td>\n",
              "      <td>20</td>\n",
              "      <td>23.948598</td>\n",
              "      <td>7.723242</td>\n",
              "      <td>3.100848</td>\n",
              "      <td>0.543767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>word</td>\n",
              "      <td>5</td>\n",
              "      <td>9.173989</td>\n",
              "      <td>4.122005</td>\n",
              "      <td>2.225614</td>\n",
              "      <td>0.516832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word</td>\n",
              "      <td>10</td>\n",
              "      <td>15.219684</td>\n",
              "      <td>7.577701</td>\n",
              "      <td>2.008483</td>\n",
              "      <td>0.522316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>word</td>\n",
              "      <td>20</td>\n",
              "      <td>25.131810</td>\n",
              "      <td>10.673344</td>\n",
              "      <td>2.354633</td>\n",
              "      <td>0.581301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   task  top_k  collision_share_%  sample_share_%      lift  \\\n",
              "0  sent      5           8.644860        2.500121  3.457776   \n",
              "1  sent     10          14.427570        4.820970  2.992670   \n",
              "2  sent     20          23.948598        7.723242  3.100848   \n",
              "3  word      5           9.173989        4.122005  2.225614   \n",
              "4  word     10          15.219684        7.577701  2.008483   \n",
              "5  word     20          25.131810       10.673344  2.354633   \n",
              "\n",
              "   collision_given_error  \n",
              "0               0.494983  \n",
              "1               0.542857  \n",
              "2               0.543767  \n",
              "3               0.516832  \n",
              "4               0.522316  \n",
              "5               0.581301  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def topk_writer_summary(writer_stats, task, top_ks=[5, 10, 20]):\n",
        "    results = []\n",
        "    df_task = writer_stats[writer_stats[\"task\"] == task].copy()\n",
        "    df_task = df_task.sort_values(\"n_collision_uids\", ascending=False)\n",
        "\n",
        "    total_collisions = df_task[\"n_collision_uids\"].sum()\n",
        "    total_samples = df_task[\"n_samples\"].sum()\n",
        "\n",
        "    for k in top_ks:\n",
        "        topk = df_task.head(k)\n",
        "\n",
        "        # shares\n",
        "        coll_share = 100 * topk[\"n_collision_uids\"].sum() / total_collisions\n",
        "        sample_share = 100 * topk[\"n_samples\"].sum() / total_samples\n",
        "        lift = coll_share / sample_share if sample_share > 0 else np.nan\n",
        "\n",
        "        # collision given error (weighted)\n",
        "        total_errors_topk = topk[\"n_errors\"].sum()\n",
        "        total_collisions_topk = topk[\"n_collision_uids\"].sum()\n",
        "        collision_given_error = (\n",
        "            total_collisions_topk / total_errors_topk\n",
        "            if total_errors_topk > 0 else np.nan\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            \"task\": task,\n",
        "            \"top_k\": k,\n",
        "            \"collision_share_%\": round(coll_share, 6),\n",
        "            \"sample_share_%\": round(sample_share, 6),\n",
        "            \"lift\": round(lift, 6),\n",
        "            \"collision_given_error\": round(collision_given_error, 6)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run for both tasks\n",
        "summary_sent = topk_writer_summary(writer_stats, \"sent\")\n",
        "summary_word = topk_writer_summary(writer_stats, \"word\")\n",
        "\n",
        "topk_summary = pd.concat([summary_sent, summary_word], ignore_index=True)\n",
        "topk_summary.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>top_k</th>\n",
              "      <th>lift</th>\n",
              "      <th>collision_share_%</th>\n",
              "      <th>sample_share_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sent</td>\n",
              "      <td>5</td>\n",
              "      <td>3.457776</td>\n",
              "      <td>8.644860</td>\n",
              "      <td>2.500121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sent</td>\n",
              "      <td>10</td>\n",
              "      <td>2.992670</td>\n",
              "      <td>14.427570</td>\n",
              "      <td>4.820970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sent</td>\n",
              "      <td>20</td>\n",
              "      <td>3.100848</td>\n",
              "      <td>23.948598</td>\n",
              "      <td>7.723242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>word</td>\n",
              "      <td>5</td>\n",
              "      <td>2.225614</td>\n",
              "      <td>9.173989</td>\n",
              "      <td>4.122005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word</td>\n",
              "      <td>10</td>\n",
              "      <td>2.008483</td>\n",
              "      <td>15.219684</td>\n",
              "      <td>7.577701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>word</td>\n",
              "      <td>20</td>\n",
              "      <td>2.354633</td>\n",
              "      <td>25.131810</td>\n",
              "      <td>10.673344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   task  top_k      lift  collision_share_%  sample_share_%\n",
              "0  sent      5  3.457776           8.644860        2.500121\n",
              "1  sent     10  2.992670          14.427570        4.820970\n",
              "2  sent     20  3.100848          23.948598        7.723242\n",
              "3  word      5  2.225614           9.173989        4.122005\n",
              "4  word     10  2.008483          15.219684        7.577701\n",
              "5  word     20  2.354633          25.131810       10.673344"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "task  top_k     lift  collision_share_%  sample_share_%\n",
            "sent      5 3.457776           8.644860        2.500121\n",
            "sent     10 2.992670          14.427570        4.820970\n",
            "sent     20 3.100848          23.948598        7.723242\n",
            "word      5 2.225614           9.173989        4.122005\n",
            "word     10 2.008483          15.219684        7.577701\n",
            "word     20 2.354633          25.131810       10.673344\n"
          ]
        }
      ],
      "source": [
        "def concentration_collision_vs_samples(writer_stats: pd.DataFrame, task: str, topk=(5,10,20)):\n",
        "    sub = writer_stats[writer_stats[\"task\"] == task].copy()\n",
        "\n",
        "    # Total collisions and samples\n",
        "    total_coll = sub[\"n_collision_uids\"].sum()\n",
        "    total_samp = sub[\"n_samples\"].sum()\n",
        "\n",
        "    # Rank writers by collisions\n",
        "    sub = sub.sort_values(\"n_collision_uids\", ascending=False)\n",
        "\n",
        "    out = []\n",
        "    for k in topk:\n",
        "        top = sub.head(k)\n",
        "        coll_share = top[\"n_collision_uids\"].sum() / total_coll if total_coll > 0 else np.nan\n",
        "        samp_share = top[\"n_samples\"].sum() / total_samp if total_samp > 0 else np.nan\n",
        "        out.append({\n",
        "            \"task\": task,\n",
        "            \"top_k\": k,\n",
        "            \"collision_share\": coll_share,\n",
        "            \"sample_share\": samp_share,\n",
        "            \"lift\": (coll_share / samp_share) if (samp_share and samp_share > 0) else np.nan\n",
        "        })\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "conc2 = pd.concat([\n",
        "    concentration_collision_vs_samples(writer_stats, \"sent\"),\n",
        "    concentration_collision_vs_samples(writer_stats, \"word\")\n",
        "], ignore_index=True)\n",
        "\n",
        "conc2[\"collision_share_%\"] = 100 * conc2[\"collision_share\"]\n",
        "conc2[\"sample_share_%\"]    = 100 * conc2[\"sample_share\"]\n",
        "conc2 = conc2.drop(columns=[\"collision_share\",\"sample_share\"])\n",
        "\n",
        "display(conc2.sort_values([\"task\",\"top_k\"]))\n",
        "print(conc2.sort_values([\"task\",\"top_k\"]).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>id_writer</th>\n",
              "      <th>n_samples</th>\n",
              "      <th>n_errors</th>\n",
              "      <th>n_collision_uids</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>collision_rate</th>\n",
              "      <th>collision_given_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>sent</td>\n",
              "      <td>1001</td>\n",
              "      <td>233</td>\n",
              "      <td>140</td>\n",
              "      <td>49</td>\n",
              "      <td>0.600858</td>\n",
              "      <td>0.210300</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>sent</td>\n",
              "      <td>s=4_k-]/</td>\n",
              "      <td>117</td>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "      <td>0.316239</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.729730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>sent</td>\n",
              "      <td>E/r9K[,0</td>\n",
              "      <td>58</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>sent</td>\n",
              "      <td>FxdJc.NU</td>\n",
              "      <td>48</td>\n",
              "      <td>45</td>\n",
              "      <td>24</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>sent</td>\n",
              "      <td>8r/s0Q_2</td>\n",
              "      <td>60</td>\n",
              "      <td>49</td>\n",
              "      <td>24</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.489796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>sent</td>\n",
              "      <td>N)H]ne[#</td>\n",
              "      <td>49</td>\n",
              "      <td>28</td>\n",
              "      <td>22</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.448980</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sent</td>\n",
              "      <td>$0u2cYZw</td>\n",
              "      <td>46</td>\n",
              "      <td>28</td>\n",
              "      <td>22</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>sent</td>\n",
              "      <td>pzT(/e8a</td>\n",
              "      <td>52</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.365385</td>\n",
              "      <td>0.487179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>sent</td>\n",
              "      <td>[h(NNQxU</td>\n",
              "      <td>57</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>0.508772</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.620690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>sent</td>\n",
              "      <td>dUa!]%&amp;2</td>\n",
              "      <td>73</td>\n",
              "      <td>30</td>\n",
              "      <td>18</td>\n",
              "      <td>0.410959</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>sent</td>\n",
              "      <td>Ft(xx)Rh</td>\n",
              "      <td>259</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>0.119691</td>\n",
              "      <td>0.069498</td>\n",
              "      <td>0.580645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>sent</td>\n",
              "      <td>cH!AXNb§</td>\n",
              "      <td>51</td>\n",
              "      <td>24</td>\n",
              "      <td>17</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>sent</td>\n",
              "      <td>K=yg)c0A</td>\n",
              "      <td>67</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>0.477612</td>\n",
              "      <td>0.253731</td>\n",
              "      <td>0.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>sent</td>\n",
              "      <td>ZkZj$,A(</td>\n",
              "      <td>59</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>0.542373</td>\n",
              "      <td>0.288136</td>\n",
              "      <td>0.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>sent</td>\n",
              "      <td>pY]7Th-#</td>\n",
              "      <td>66</td>\n",
              "      <td>44</td>\n",
              "      <td>17</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.257576</td>\n",
              "      <td>0.386364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>word</td>\n",
              "      <td>1001</td>\n",
              "      <td>352</td>\n",
              "      <td>201</td>\n",
              "      <td>70</td>\n",
              "      <td>0.571023</td>\n",
              "      <td>0.198864</td>\n",
              "      <td>0.348259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>word</td>\n",
              "      <td>3ZTCBzjm</td>\n",
              "      <td>264</td>\n",
              "      <td>85</td>\n",
              "      <td>67</td>\n",
              "      <td>0.321970</td>\n",
              "      <td>0.253788</td>\n",
              "      <td>0.788235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>word</td>\n",
              "      <td>1002</td>\n",
              "      <td>109</td>\n",
              "      <td>97</td>\n",
              "      <td>45</td>\n",
              "      <td>0.889908</td>\n",
              "      <td>0.412844</td>\n",
              "      <td>0.463918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>word</td>\n",
              "      <td>R3tyzUzm</td>\n",
              "      <td>95</td>\n",
              "      <td>63</td>\n",
              "      <td>41</td>\n",
              "      <td>0.663158</td>\n",
              "      <td>0.431579</td>\n",
              "      <td>0.650794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>word</td>\n",
              "      <td>tO2poK</td>\n",
              "      <td>176</td>\n",
              "      <td>59</td>\n",
              "      <td>38</td>\n",
              "      <td>0.335227</td>\n",
              "      <td>0.215909</td>\n",
              "      <td>0.644068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>word</td>\n",
              "      <td>1006</td>\n",
              "      <td>81</td>\n",
              "      <td>64</td>\n",
              "      <td>38</td>\n",
              "      <td>0.790123</td>\n",
              "      <td>0.469136</td>\n",
              "      <td>0.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>word</td>\n",
              "      <td>SOnGNT</td>\n",
              "      <td>117</td>\n",
              "      <td>56</td>\n",
              "      <td>35</td>\n",
              "      <td>0.478632</td>\n",
              "      <td>0.299145</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>word</td>\n",
              "      <td>GS3V2Dw?</td>\n",
              "      <td>273</td>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0.124542</td>\n",
              "      <td>0.693878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>word</td>\n",
              "      <td>FxdJc.NU</td>\n",
              "      <td>50</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>word</td>\n",
              "      <td>1005</td>\n",
              "      <td>314</td>\n",
              "      <td>111</td>\n",
              "      <td>32</td>\n",
              "      <td>0.353503</td>\n",
              "      <td>0.101911</td>\n",
              "      <td>0.288288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>word</td>\n",
              "      <td>8r/s0Q_2</td>\n",
              "      <td>36</td>\n",
              "      <td>33</td>\n",
              "      <td>31</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.939394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>word</td>\n",
              "      <td>6n2ao!1i</td>\n",
              "      <td>119</td>\n",
              "      <td>45</td>\n",
              "      <td>31</td>\n",
              "      <td>0.378151</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.688889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>word</td>\n",
              "      <td>pY]7Th-#</td>\n",
              "      <td>83</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>0.361446</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>word</td>\n",
              "      <td>pOHXtw</td>\n",
              "      <td>69</td>\n",
              "      <td>63</td>\n",
              "      <td>30</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>word</td>\n",
              "      <td>EwXuxV</td>\n",
              "      <td>78</td>\n",
              "      <td>36</td>\n",
              "      <td>28</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     task id_writer  n_samples  n_errors  n_collision_uids  error_rate  \\\n",
              "68   sent      1001        233       140                49    0.600858   \n",
              "405  sent  s=4_k-]/        117        37                27    0.316239   \n",
              "170  sent  E/r9K[,0         58        28                24    0.482759   \n",
              "177  sent  FxdJc.NU         48        45                24    0.937500   \n",
              "127  sent  8r/s0Q_2         60        49                24    0.816667   \n",
              "232  sent  N)H]ne[#         49        28                22    0.571429   \n",
              "7    sent  $0u2cYZw         46        28                22    0.608696   \n",
              "395  sent  pzT(/e8a         52        39                19    0.750000   \n",
              "301  sent  [h(NNQxU         57        29                18    0.508772   \n",
              "334  sent  dUa!]%&2         73        30                18    0.410959   \n",
              "176  sent  Ft(xx)Rh        259        31                18    0.119691   \n",
              "322  sent  cH!AXNb§         51        24                17    0.470588   \n",
              "195  sent  K=yg)c0A         67        32                17    0.477612   \n",
              "294  sent  ZkZj$,A(         59        32                17    0.542373   \n",
              "392  sent  pY]7Th-#         66        44                17    0.666667   \n",
              "534  word      1001        352       201                70    0.571023   \n",
              "561  word  3ZTCBzjm        264        85                67    0.321970   \n",
              "535  word      1002        109        97                45    0.889908   \n",
              "753  word  R3tyzUzm         95        63                41    0.663158   \n",
              "923  word    tO2poK        176        59                38    0.335227   \n",
              "539  word      1006         81        64                38    0.790123   \n",
              "763  word    SOnGNT        117        56                35    0.478632   \n",
              "667  word  GS3V2Dw?        273        49                34    0.179487   \n",
              "658  word  FxdJc.NU         50        44                33    0.880000   \n",
              "538  word      1005        314       111                32    0.353503   \n",
              "601  word  8r/s0Q_2         36        33                31    0.916667   \n",
              "584  word  6n2ao!1i        119        45                31    0.378151   \n",
              "904  word  pY]7Th-#         83        40                30    0.481928   \n",
              "903  word    pOHXtw         69        63                30    0.913043   \n",
              "652  word    EwXuxV         78        36                28    0.461538   \n",
              "\n",
              "     collision_rate  collision_given_error  \n",
              "68         0.210300               0.350000  \n",
              "405        0.230769               0.729730  \n",
              "170        0.413793               0.857143  \n",
              "177        0.500000               0.533333  \n",
              "127        0.400000               0.489796  \n",
              "232        0.448980               0.785714  \n",
              "7          0.478261               0.785714  \n",
              "395        0.365385               0.487179  \n",
              "301        0.315789               0.620690  \n",
              "334        0.246575               0.600000  \n",
              "176        0.069498               0.580645  \n",
              "322        0.333333               0.708333  \n",
              "195        0.253731               0.531250  \n",
              "294        0.288136               0.531250  \n",
              "392        0.257576               0.386364  \n",
              "534        0.198864               0.348259  \n",
              "561        0.253788               0.788235  \n",
              "535        0.412844               0.463918  \n",
              "753        0.431579               0.650794  \n",
              "923        0.215909               0.644068  \n",
              "539        0.469136               0.593750  \n",
              "763        0.299145               0.625000  \n",
              "667        0.124542               0.693878  \n",
              "658        0.660000               0.750000  \n",
              "538        0.101911               0.288288  \n",
              "601        0.861111               0.939394  \n",
              "584        0.260504               0.688889  \n",
              "904        0.361446               0.750000  \n",
              "903        0.434783               0.476190  \n",
              "652        0.358974               0.777778  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "top_writers = (writer_stats.sort_values([\"task\",\"n_collision_uids\"], ascending=[True, False])\n",
        "               .groupby(\"task\", group_keys=False)\n",
        "               .head(15)[[\"task\",\"id_writer\",\"n_samples\",\"n_errors\",\"n_collision_uids\",\n",
        "                          \"error_rate\",\"collision_rate\",\"collision_given_error\"]])\n",
        "\n",
        "display(top_writers)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
